## Быстрая сортировка

В алгоритме быстрой сортировки (quick sort) мы выделяем опорный элемент и разбиваем массив на две части: в одной части элементы меньше опорного, в другой –– больше. Элементы, равные опорному, добавляют в любую группу. Затем рекурсивно вызываем алгоритм на двух выделенных группах и соединяем отсортированные левую и правую части с опорным элементом в конечный результат. Условие остановки рекурсии –– сортировка массива из одного или нуля элементов.

Для массива `[6,5,3,1,8,7,2,4]` быстрая сортировка происходит так:

![image](https://pictures.s3.yandex.net/resources/S1_03_06_fastsorting_1_1592472427.png)

_Разбиение массива на части в быстрой сортировке. Синим отмечен опорный элемент._

Заливкой мы отметили опорный элемент. В этом случае опорный элемент –– последний элемент в массиве.

Затем мы соединяем все отсортированные части в итоговый результат:

![image](https://pictures.s3.yandex.net/resources/S1_03_07_fastsorting_1_1592472473.png)

_Соединение отсортированных частей в конечный массив._

Запишем алгоритм быстрой сортировки `quickSort(arr, start, end)`:

1.  Принимаем на вход массив `arr` и индексы начала и конца участка `start` и `end`, который нужно отсортировать. При первом запуске они будут `0` и `arr.length - 1`.
2.  Если `end ≤ start`, выходим из алгоритма и возвращаем входной массив. Сортировать нечего.
3.  Нужно выбрать опорный элемент и переставить элементы в массиве. Элементы меньшие или равные опорному окажутся слева, большие — справа. Пройдём по шагам:
    
    3.1 Выбираем опорный элемент как последний элемент на участке `pivotValue = arr[end]`. Выставляем `pivotIndex = start`.
    
    3.2 В цикле от `start` до `end`, где текущий индекс будет `i`, сравниваем `arr[i]` с `pivotValue`.
    
    3.3 Если `arr[i] < pivotValue`, меняем местами значения с индексами `i` и `pivotIndex`, увеличиваем `pivotIndex` на единицу.
    
    3.4 После окончания цикла меняем местами значения в `pivotIndex` и `end`, возвращаем `pivotIndex`.
    
4.  Запускаем алгоритм отдельно на левой и правой частях как `quickSort(arr, start, pivotIndex - 1)` и `quickSort(arr, pivotIndex + 1, end)`.
    

### Анализ сложности алгоритма

В позитивном сценарии выбираем опорный элемент так, что он делит массив с нечётным количеством элементов пополам. В массиве с чётным –– части отличаются на единицу.

Построим дерево решения задачи с размеров входных данных на каждом этапе:

![image](https://pictures.s3.yandex.net/resources/S1_03_08_positivefastsorting_1_1592472717.png)

_Дерево решения для быстрой сортировки в позитивном сценарии_

В узлах дерева указан размер массива. На первом шаге — `n`, на втором — `≤ n/2`, на третьем — `≤ n/4`. Это число завышено, ведь опорный элемент не участвует в сортировке. На самом деле размер массива на втором этапе — `(n - 1) / 2`, а на третьем — `(n - 3) / 4`. Допускаем погрешность для простоты расчётов.

На каждом шаге мы уменьшаем длину массива в два раза. Поэтому высота дерева log2(n). Для массива длиной 4 понадобится log2(4)=2 шага, а для массива длиной 8 — log2(8)=3.

На первом этапе суммарно понадобится `n` операций, на втором `2 * n/2`, а на третьем `4 * n/4`. И так до `n * n /n`. Сложность каждого шага `О(n)`.

Повторим: получится `log2(n)` шагов, сложность каждого `О(n)`. Общая сложность в лучшем случае `n * log2(n)`. Можно записать её так: `Ω(n * log(n))`. Опускаем основание логарифма — по математической формуле оно значения не имеет:

![image](https://pictures.s3.yandex.net/resources/__2020-04-05__15.42.14_1_1592472748.png)

Всегда можно представить логарифм по основанию `a` как логарифм по основанию `b`, делённому на константу. Её мы не учитываем в анализе сложности. Поэтому все логарифмы в оценке сложности равносильны.

В негативном сценарии мы выбираем неудачный опорный элемент. Он делит массив так, что все элементы попадают в одну часть.

![image](https://pictures.s3.yandex.net/resources/S1_03_09_negativefastsorting_1_1592472767.png)

Сделаем `n` шагов, на каждом сравним все элементы с опорным. За каждый проход элементов становится меньше всего на один. Понадобится `n + (n-1) + (n-2) + ... + 1` операций. Вычислим сложность: `(n+1)/2 * n = O(n^2)`.

При неудачном выборе опорного элемента и плохих входных данных, например однородных, сложность этого алгоритма равна сложности неэффективных алгоритмов. Их мы рассматривали в прошлых уроках.

В базовом случае опорный элемент поделит массив на две неравные части. Предположим, что в левую часть попадёт четверть элементов, а в правую — три четверти:

![image](https://pictures.s3.yandex.net/resources/S1_03_10_basefastsorting_1_1592472786.png)

_Дерево решения для быстрой сортировки в базовом сценарии_

Высота самого левого пути по дереву `log4(n)`, высота самого правого — `log4/3(n)`. На каждом шаге до `log4(n)` сделаем `n` операций: `n/4 + 3n/4 = n`, `n/16+3n/16+3n/16+9n/16 = n`. До `log4/3(n)` — меньше, потому что одна ветка дерева уже закончится.

Для простоты посчитаем самое большое количество операций по самой длинной ветке. Получим сложность: `Θ(n*log4/3(n)) = Θ(n * log(n))`.

Пространственная сложность алгоритма `О(log(n))`. Алгоритм рекурсивный и каждый вызов функции до момента подсчёта финального результата вызывает новую запись в стеке вызовов. Максимальное число записей на стеке равно максимальной высоте дерева. Высота дерева равна логарифму от размера массива.

### Выбор опорного элемента

Любой элемент массива может быть опорным. Алгоритм работает правильно с любым опорным элементом, но с разной скоростью. Если выбрать опорный элемент неудачно, в одной части массива будет значительно больше элементов, чем во второй. Это замедлит работу алгоритма.

Самый удачный опорный элемент –– медиана массива. Она разделит массив на две примерно равные части. Но вычислять медиану дорого, придётся сортировать массив. Поэтому обычно опорный элемент определяют так:

-   выбирают элемент в массиве случайным образом;
-   выбирают медианный элемент по первому, среднему и последнему элементам массива.

В текстовом описании алгоритма в начале урока мы упростили задачу и сделали опорным последний элемент в массиве. Можно выбрать элемент другим способом. Тогда разобьём пункт 3.1 на два шага:

1.  Выбираем опорный элемент любым описанным способом. Его индекс сохраняем в `pivotIndex`, значение в `pivotValue`.
2.  Переставляем местами элементы в `pivotIndex` и `end`. Опорный элемент должен оказаться последним, чтобы остальная часть алгоритма работала как раньше.